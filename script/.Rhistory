ggplot(mapping = aes(x = reorder(provinsi, -sdp_per1000), y = sdp_per1000)) +
geom_bar(stat = "identity") +
coord_flip()
# which provinces have the highest incarceration rates?
prov_level_2021 %>%
filter(tanggal_sdp == as.Date("2021-08-16", format("%Y-%m-%d"))) %>%
ggplot(mapping = aes(x = reorder(provinsi, -sdp_per1000), y = sdp_per1000)) +
geom_bar(stat = "identity") +
coord_flip() +
theme_tufte()
library(ggthemes)
install.packages("ggthemes")
library(ggthemes)
# which provinces have the highest incarceration rates?
prov_level_2021 %>%
filter(tanggal_sdp == as.Date("2021-08-16", format("%Y-%m-%d"))) %>%
ggplot(mapping = aes(x = reorder(provinsi, -sdp_per1000), y = sdp_per1000)) +
geom_bar(stat = "identity") +
coord_flip() +
theme_tufte()
# which provinces have the highest incarceration rates?
prov_level_2021 %>%
filter(tanggal_sdp == as.Date("2021-08-16", format("%Y-%m-%d"))) %>%
ggplot(mapping = aes(x = reorder(provinsi, -sdp_per1000), y = sdp_per1000)) +
geom_bar(stat = "identity") +
coord_flip() +
theme_bw()
# which provinces have the highest incarceration rates?
prov_level_2021 %>%
filter(tanggal_sdp == as.Date("2021-08-16", format("%Y-%m-%d"))) %>%
ggplot(mapping = aes(x = reorder(provinsi, -sdp_per1000), y = sdp_per1000)) +
geom_bar(stat = "identity") +
labs(y = "Incarcerated per 1000 Population",
x = "Provinces",
title = "Incarceration Rates per 1000 Population, as of 16 August 2021")
# which provinces have the highest incarceration rates?
prov_level_2021 %>%
filter(tanggal_sdp == as.Date("2021-08-16", format("%Y-%m-%d"))) %>%
ggplot(mapping = aes(x = reorder(provinsi, -sdp_per1000), y = sdp_per1000)) +
geom_bar(stat = "identity") +
labs(y = "Incarcerated per 1000 Population",
x = "Provinces",
title = "Incarceration Rates per 1000 Population, as of 16 August 2021") +
coord_flip() +
theme_bw()
# what are the trend lines of incarceration rates across provinces in 2021?
prov_level_2021 %>%
ggplot(aes(x = tanggal_sdp, y = sdp_per1000, color = provinsi)) +
geom_line()
prov_level_2021$year <- format(prov_level_2021$tanggal_sdp, format = "%Y")
# what are the trend lines of incarceration rates across provinces in 2021?
prov_level_2021$year <- format(prov_level_2021$tanggal_sdp, format = "%Y")
prov_level_2021 %>%
filter(year == 2021) %>%
ggplot(aes(x = tanggal_sdp, y = sdp_per1000, color = provinsi)) +
geom_line()
susenas_2019 <- "C:/Users/Sean Hambali/Desktop/DATA/SUSENAS/2019"
# loading the exp cap data
expcap_2019 <- read_dta(paste0(susenas_2019, "expcap_prov_2019.dta"))
susenas_2019 <- "C:/Users/Sean Hambali/Desktop/DATA/SUSENAS/2019/"
# loading the exp cap data
expcap_2019 <- read_dta(paste0(susenas_2019, "expcap_prov_2019.dta"))
# merging the province level data with the expcap data
prov_level_2021 <- merge(prov_level_2021, expcap_2019, by.x = c("kode"), by.y = c("kode_prov"), all.x = T)
View(prov_level_2021)
# are these rates showing relationships with median expenditure per capita?
prov_level_2021 %>%
filter(tanggal_sdp == as.Date("2021-08-16", format("%Y-%m-%d"))) %>%
mutate(
lexp_cap = log(exp_cap)
) %>%
ggplot(aes(lexp_cap, sdp_per1000)) +
geom_point() + geom_smooth()
# are these rates showing relationships with median expenditure per capita?
prov_level_2021 %>%
filter(tanggal_sdp == as.Date("2021-08-16", format("%Y-%m-%d"))) %>%
mutate(
lexp_cap = log(exp_cap)
) %>%
ggplot(aes(lexp_cap, sdp_per1000)) +
geom_point() + geom_smooth() +
labs(y = "Incarcerated per 1000 Population",
x = "Log Expenditure per Capita in 2019",
title = "Incarceration Rates and Expenditure per Capita Levels")
# are these rates showing relationships with median expenditure per capita?
prov_level_2021 %>%
filter(tanggal_sdp == as.Date("2021-08-16", format("%Y-%m-%d"))) %>%
mutate(
lexp_cap = log(exp_cap)
) %>%
ggplot(aes(lexp_cap, sdp_per1000)) +
geom_point() + geom_smooth() +
labs(y = "Incarcerated per 1000 Population",
x = "Log Expenditure per Capita in 2019",
title = "Incarceration Rates and Expenditure per Capita Levels") +
theme_bw()
# are these rates showing relationships with median expenditure per capita?
prov_level_2021 %>%
filter(tanggal_sdp == as.Date("2021-08-16", format("%Y-%m-%d"))) %>%
mutate(
lexp_cap = log(exp_cap)
) %>%
ggplot(aes(lexp_cap, sdp_per1000)) +
geom_point() + geom_smooth() +
labs(y = "Incarcerated per 1000 Population",
x = "Log Median Expenditure per Capita in 2019",
title = "Incarceration Rates and Expenditure per Capita Levels") +
theme_bw()
# are these rates showing relationships with median expenditure per capita?
prov_level_2021 %>%
filter(tanggal_sdp == as.Date("2021-08-16", format("%Y-%m-%d"))) %>%
mutate(
lexp_cap = log(exp_cap)
) %>%
ggplot(aes(lexp_cap, sdp_per1000)) +
geom_point() + geom_smooth() +
labs(y = "Incarcerated per 1000 Population",
x = "Log Median Expenditure per Capita in 2019",
title = "Incarceration Rates and Expenditure per Capita Levels") +
theme_bw() +
theme(plot.title = element_text(hjust = .5))
# are these rates showing relationships with median expenditure per capita?
prov_level_2021 %>%
filter(tanggal_sdp == as.Date("2021-08-16", format("%Y-%m-%d"))) %>%
mutate(
lexp_cap = log(exp_cap)
) %>%
ggplot(aes(lexp_cap, sdp_per1000)) +
geom_point() + geom_abline() +
labs(y = "Incarcerated per 1000 Population",
x = "Log Median Expenditure per Capita in 2019",
title = "Incarceration Rates and Expenditure per Capita Levels") +
theme_bw() +
theme(plot.title = element_text(hjust = .5))
# are these rates showing relationships with median expenditure per capita?
prov_level_2021 %>%
filter(tanggal_sdp == as.Date("2021-08-16", format("%Y-%m-%d"))) %>%
mutate(
lexp_cap = log(exp_cap)
) %>%
ggplot(aes(lexp_cap, sdp_per1000)) +
geom_point() + geom_smooth(method = lm) +
labs(y = "Incarcerated per 1000 Population",
x = "Log Median Expenditure per Capita in 2019",
title = "Incarceration Rates and Expenditure per Capita Levels") +
theme_bw() +
theme(plot.title = element_text(hjust = .5))
rm(list=ls())
# loading the necessary packages
library(tidyverse)
library(rvest)
library(data.table)
library(haven)
# setting the working directories
data <- "C:/Users/Sean Hambali/Desktop/DATA/"
rout <- "C:/Users/Sean Hambali/Documents/Github/siranap_hospital_data/rdata/"
csvout <- "C:/Users/Sean Hambali/Documents/Github/siranap_hospital_data/csv/"
dtaout <- "C:/Users/Sean Hambali/Documents/Github/siranap_hospital_data/dta/"
# importing the kabupaten correspondence file
district_list <- read.table(paste0(data, "Kode KabupatenKota.csv"), sep = "\t")
names(district_list) <- c("district_code", "district_name", "province_code")
district_codes <- as.character(district_list$district_code)
# building the scraper!
# COVID Beds ----
for (i in district_codes) {
# getting the province codes
prov_code <- str_sub(i, 1,2)
district_code <- i
# specifying the base url
url <- paste0("https://yankes.kemkes.go.id/app/siranap/rumah_sakit?jenis=1&propinsi=",
prov_code,
"prop&kabkota=",
district_code)
base_html <- read_html(url)
# getting the list of hospitals in Jakarta Pusat
list_hospital_html <- html_nodes(base_html, "h5")
list_hospital <- html_text(list_hospital_html)
# getting the hospital address
address_html <- html_nodes(base_html, ".col-md-7 p")
address <- html_text(address_html)
# queue data
queue_html <- html_nodes(base_html, ".mb-0:nth-child(3)")
queue <- html_text(queue_html) %>%
gsub("\r\n", "", .) %>%
str_trim(side = c("both", "left", "right")) %>%
str_squish()
# update time
update_html <- html_nodes(base_html, ".mb-0:nth-child(4)")
update <- html_text(update_html) %>%
gsub("\r\n", "", .) %>%
gsub("(diupdate|yang lalu)", "", .) %>%
str_trim(side = c("both", "left", "right")) %>%
str_squish()
# telephone number
tlp_html <- html_nodes(base_html, ".text-right span")
tlp <- html_text(tlp_html)
tlp <- tlp[-1]
# getting the bed availability data
bed_availability_html <- html_nodes(base_html, ".mb-1+ .mb-0")
bed_availability <- html_text(bed_availability_html) %>%
gsub("\r\n", "", .) %>%
str_trim(side = c("both", "left", "right")) %>%
str_squish()
# combining into df for COVID beds
half_list <- tibble(
hospital = list_hospital,
address = address,
bed_availability = bed_availability,
queue = queue,
last_update = update,
tlp_number = tlp,
province = prov_code,
district = district_code,
scraped_at = Sys.time(),
bed_type = "COVID-19"
)
# get today's date
date <- Sys.Date() %>%
format("%m%d")
# saving the data
assign(paste0("covid_bed_data_", district_code, "_", date),
half_list)
}
# APPENDING THE COVID BEDS DATA ----
dflist <- lapply(paste0("covid_bed_data_",district_codes,"_",date), get)
base_data <- rbindlist(dflist)
saveRDS(base_data, file=paste0(rout, "covid_bed_data_all", "_", date, ".rds"))
write.csv(base_data, paste0(csvout, "covid_bed_data_all", "_", date, ".csv"))
write_dta(base_data, paste0(dtaout, "covid_bed_data_all", "_", date, ".dta"))
# Non-COVID Beds ----
for (i in district_codes) {
# getting the province codes
prov_code <- str_sub(i, 1,2)
district_code <- i
# specifying the base url
url <- paste0("https://yankes.kemkes.go.id/app/siranap/rumah_sakit?jenis=2&propinsi=",
prov_code,
"prop&kabkota=",
district_code)
base_html <- read_html(url)
# getting the list of hospitals in Jakarta Pusat
list_hospital_html <- html_nodes(base_html, "h5")
list_hospital <- html_text(list_hospital_html)
# getting the hospital address
address_html <- html_nodes(base_html, "p")
address <- html_text(address_html)
# beds
bed_html <- html_nodes(base_html, ".pt-md-0")
bed <- html_text(bed_html) %>%
gsub("\r\n", "", .) %>%
str_trim(side = c("both", "left", "right")) %>%
str_squish()
# class-1 beds
bed_class1 <- str_extract_all(bed, "[0-9]+ Bed Kosong Kelas I ") %>%
lapply(function(x) if(identical(x, character(0))) NA_character_ else x) %>%
lapply(FUN = function(t) as.numeric(gsub(" Bed Kosong Kelas I", "", x = t))) %>%
lapply(.,FUN = sum) %>%
unlist(., use.names = F)
# class-2 beds
bed_class2 <- str_extract_all(bed, "[0-9]+ Bed Kosong Kelas II ") %>%
lapply(function(x) if(identical(x, character(0))) NA_character_ else x) %>%
lapply(FUN = function(t) as.numeric(gsub(" Bed Kosong Kelas II", "", x = t))) %>%
lapply(.,FUN = sum) %>%
unlist(., use.names = F)
# class-3 beds
bed_class3 <- str_extract_all(bed, "[0-9]+ Bed Kosong Kelas III ") %>%
lapply(function(x) if(identical(x, character(0))) NA_character_ else x) %>%
lapply(FUN = function(t) as.numeric(gsub(" Bed Kosong Kelas III", "", x = t))) %>%
lapply(.,FUN = sum) %>%
unlist(., use.names = F)
# update time (taking the minimum times)
update_class1 <- str_extract_all(bed, "Kelas I Di Ruang [a-zA-Z\\& ]+ [0-9]+ (jam|menit)") %>%
lapply(function(x) if(identical(x, character(0))) NA_character_ else x) %>%
lapply(function(t) gsub("[a-zA-Z\\& ]+ diupdate", "", x=t)) %>%
map(1) %>%
unlist(., use.names = F) %>%
str_trim(side = c("both", "left", "right")) %>%
str_squish()
update_class2 <- str_extract_all(bed, "Kelas II Di Ruang [a-zA-Z\\& ]+ [0-9]+ (jam|menit)") %>%
lapply(function(x) if(identical(x, character(0))) NA_character_ else x) %>%
lapply(function(t) gsub("[a-zA-Z\\& ]+ diupdate", "", x=t))%>%
map(1) %>%
unlist(., use.names = F) %>%
str_trim(side = c("both", "left", "right")) %>%
str_squish()
update_class3 <- str_extract_all(bed, "Kelas III Di Ruang [a-zA-Z\\& ]+ [0-9]+ (jam|menit)") %>%
lapply(function(x) if(identical(x, character(0))) NA_character_ else x) %>%
lapply(function(t) gsub("[a-zA-Z\\& ]+ diupdate", "", x=t)) %>%
map(1) %>%
unlist(., use.names = F) %>%
str_trim(side = c("both", "left", "right")) %>%
str_squish()
# telephone number
tlp_html <- html_nodes(base_html, ".text-right span")
tlp <- html_text(tlp_html)
tlp <- tlp[-1]
# combining into df for COVID beds
half_list <- tibble(
hospital = list_hospital,
address = address,
bed_class1 = bed_class1,
last_update_class1 = update_class1,
bed_class2 = bed_class2,
last_update_class2 = update_class2,
bed_class3 = bed_class3,
last_update_class3 = update_class3,
tlp_number = tlp,
province = prov_code,
district = district_code,
scraped_at = Sys.time(),
bed_type = "Non COVID-19"
)
# get today's date
date <- Sys.Date() %>%
format("%m%d")
# saving the data
assign(paste0("noncovid_bed_data_", district_code, "_", date),
half_list)
}
# APPENDING THE NON-COVID BEDS DATA ----
dflist <- lapply(paste0("noncovid_bed_data_",district_codes,"_",date), get)
base_data <- rbindlist(dflist)
saveRDS(base_data, file=paste0(rout, "noncovid_bed_data_all", "_", date, ".rds"))
write.csv(base_data, paste0(csvout, "noncovid_bed_data_all", "_", date, ".csv"))
write_dta(base_data, paste0(dtaout, "noncovid_bed_data_all", "_", date, ".dta"))
# remove previous environment
rm(list=ls())
# Loading the required library
library(tidyverse)
library(rvest)
library(janitor)
library(data.table)
library(epiDisplay)
library(haven)
library(fuzzyjoin)
library(ggthemes)
# removing prior objects
rm(list=ls())
# storing the working directories
wd_2012 <- "C:/Users/Sean Hambali/Documents/GitHub/prisondata_ID/2012/"
wd_2013 <- "C:/Users/Sean Hambali/Documents/GitHub/prisondata_ID/2013/"
wd_2014 <- "C:/Users/Sean Hambali/Documents/GitHub/prisondata_ID/2014/"
wd_2015 <- "C:/Users/Sean Hambali/Documents/GitHub/prisondata_ID/2015/"
wd_2016 <- "C:/Users/Sean Hambali/Documents/GitHub/prisondata_ID/2016/"
wd_2017 <- "C:/Users/Sean Hambali/Documents/GitHub/prisondata_ID/2017/"
wd_2018 <- "C:/Users/Sean Hambali/Documents/GitHub/prisondata_ID/2018/"
wd_2019 <- "C:/Users/Sean Hambali/Documents/GitHub/prisondata_ID/2019/"
wd_2020 <- "C:/Users/Sean Hambali/Documents/GitHub/prisondata_ID/2020/"
wd_2021 <- "C:/Users/Sean Hambali/Documents/GitHub/prisondata_ID/2021/"
script <- "C:/Users/Sean Hambali/Documents/GitHub/prisondata_ID/script/"
code_data <- "C:/Users/Sean Hambali/Desktop/DATA/"
pop_data <- "C:/Users/Sean Hambali/Desktop/DATA/Population Data/"
susenas_2019 <- "C:/Users/Sean Hambali/Desktop/DATA/SUSENAS/2019/"
# loading the exp cap data
expcap_2019 <- read_dta(paste0(susenas_2019, "expcap_prov_2019.dta"))
# loading the unemployment rate data
ur_2019 <- read_dta(paste0(code_data, "province_ur_2019.dta"))
# we first load the appended 2021 data
appended_2021 <- as_tibble(readRDS(paste0(wd_2021, "appended_2021.rds")))
# we collapse the data at the daily province level
prov_level_2021 <- appended_2021 %>%
group_by(kode, provinsi, tanggal_sdp) %>%
summarise(jumlah_sdp = sum(sdp, na.rm = T),
jumlah_sms = sum(sms, na.rm = T),
pop = first(pop[!is.na(pop)])
) %>%
mutate(
sdp_per1000 = jumlah_sdp/ pop * 1000,
sms_per1000 = jumlah_sms / pop * 1000
)
# merging the province level data with the expcap data
prov_level_2021 <- merge(prov_level_2021, expcap_2019, by.x = c("kode"), by.y = c("kode_prov"), all.x = T)
prov_level_2021 <- merge(prov_level_2021, ur_2019, by.x = c("kode"), by.y = c("prov_code"), all.x = T)
# which provinces have the highest incarceration rates?
prov_level_2021 %>%
filter(tanggal_sdp == as.Date("2021-08-16", format("%Y-%m-%d"))) %>%
ggplot(mapping = aes(x = reorder(provinsi, -sdp_per1000), y = sdp_per1000)) +
geom_bar(stat = "identity") +
labs(y = "Incarcerated per 1000 Population",
x = "Provinces",
title = "Incarceration Rates per 1000 Population, as of 16 August 2021") +
coord_flip() +
theme_bw()
# what about unemployment rates?
prov_level_2021 %>%
filter(tanggal_sdp == as.Date("2021-08-16", format("%Y-%m-%d"))) %>%
ggplot(aes(unemployment_rate, sdp_per1000)) +
geom_point() + geom_smooth(method = lm) +
labs(y = "Incarcerated per 1000 Population",
x = "Unemployment Rate in 2019",
title = "Incarceration Rates and Unemployment Rates") +
theme_bw() +
theme(plot.title = element_text(hjust = .5))
# are these rates showing relationships with median expenditure per capita?
prov_level_2021 %>%
filter(tanggal_sdp == as.Date("2021-08-16", format("%Y-%m-%d"))) %>%
mutate(
lexp_cap = log(exp_cap)
) %>%
ggplot(aes(lexp_cap, sdp_per1000)) +
geom_point() + geom_smooth(method = lm) +
labs(y = "Incarcerated per 1000 Population",
x = "Log Median Expenditure per Capita in 2019",
title = "Incarceration Rates and Expenditure per Capita Levels") +
theme_bw() +
theme(plot.title = element_text(hjust = .5))
rm(list=ls())
# Loading the required library
library(tidyverse)
library(rvest)
library(janitor)
library(data.table)
library(epiDisplay)
library(haven)
library(fuzzyjoin)
# storing the working directories
wd_2012 <- "C:/Users/Sean Hambali/Documents/GitHub/prisondata_ID/2012/"
wd_2013 <- "C:/Users/Sean Hambali/Documents/GitHub/prisondata_ID/2013/"
wd_2014 <- "C:/Users/Sean Hambali/Documents/GitHub/prisondata_ID/2014/"
wd_2015 <- "C:/Users/Sean Hambali/Documents/GitHub/prisondata_ID/2015/"
wd_2016 <- "C:/Users/Sean Hambali/Documents/GitHub/prisondata_ID/2016/"
wd_2017 <- "C:/Users/Sean Hambali/Documents/GitHub/prisondata_ID/2017/"
wd_2018 <- "C:/Users/Sean Hambali/Documents/GitHub/prisondata_ID/2018/"
wd_2019 <- "C:/Users/Sean Hambali/Documents/GitHub/prisondata_ID/2019/"
wd_2020 <- "C:/Users/Sean Hambali/Documents/GitHub/prisondata_ID/2020/"
wd_2021 <- "C:/Users/Sean Hambali/Documents/GitHub/prisondata_ID/2021/"
script <- "C:/Users/Sean Hambali/Documents/GitHub/prisondata_ID/script/"
code_data <- "C:/Users/Sean Hambali/Desktop/DATA/"
pop_data <- "C:/Users/Sean Hambali/Desktop/DATA/Population Data/"
# storing the province names
kodeprov <- read_dta(paste0(code_data, "kodeprov.dta"))
# storing the province population data
popdata <- read_dta(paste0(pop_data, "population_province_2020.dta"))
# preparing the loop!
year <- "2020"
start <- as.Date("2020-01-01", format = "%Y-%m-%d")
end <- as.Date("2020-12-31", format = "%Y-%m-%d")
date <- start
# storing the base url
base_url <- "http://smslap.ditjenpas.go.id/public/sdp/current/kanwil/all/date/"
# executing the loop!
while (date <= end) {
# storing the url
url <- paste0(base_url, format(date, "%Y-%m-%d"))
# obtaining the table
table_html <- read_html(url) %>%
html_table(fill = T)
table <- tibble(table_html[[4]])
last_row <- nrow(table)
table <- table[-last_row,]
# tidying up the variables
# cleaning the variable names
table <- table %>%
clean_names()
# storing the variables based on categories
tonumeric_vars <- c("no", "sdp", "sms", "perbedaan")
date_vars <- c("tanggal_sdp", "tanggal_sms")
# converting to numeric variables
table[tonumeric_vars] <- sapply(table[tonumeric_vars], function(x) as.numeric(gsub(",","",x)))
# converting to date variables
table[date_vars] <- sapply(table[date_vars], function(x) {
as.Date(x, format = "%d-%m-%Y", origin = "1970-01-01")
})
table[date_vars] <- lapply(table[date_vars], function(x) {as.Date(x, origin = "1970-01-01")})
# saving the data
# getting the numeric correspondences of the date
num <- as.numeric(date)
# saving the data
assign(paste0("table_", num), table)
date <- date + 1
}
# appending the data
start_num <- as.numeric(start)
end_num <- as.numeric(end)
date_list <- seq(start_num, end_num, by= 1)
table_list <- lapply(paste0("table_", date_list), get)
assign(paste0("appended_", year), rbindlist(table_list))
# next, we want to generate province identifiers
appended_2020 <- appended_2020 %>%
mutate(
provinsi = str_to_title(kanwil),
provinsi = gsub("Kanwil", "", provinsi),
provinsi = gsub("Dki", "DKI", provinsi),
provinsi = gsub("D.i.", "DI", provinsi),
provinsi = gsub("\\s+", " ", provinsi)
)
# fuzzy merge with province names
# saving the province names from the appended data
provinsi_appended <- as_tibble(appended_2020$provinsi) %>%
unique()
names(provinsi_appended) <- c("provinsi")
# saving the province names from the kode provinsi data
provinsi_kode <- as_tibble(kodeprov$provinsi) %>%
unique()
names(provinsi_kode) <- c("nama_kodeprov")
# matching from appended to kodeprov data
provinsi_appended$nama_kodeprov <- ""
for (i in 1:dim(provinsi_appended)[1]) {
nama_kode <- agrep(provinsi_appended$provinsi[i], provinsi_kode$nama_kodeprov,
ignore.case = T, value = T,
max = list(sub = 0), useBytes = T)
nama_kode <- paste0(nama_kode, "")
provinsi_appended$nama_kodeprov[i] <- nama_kode
}
# completely merging the two files
appended_2020_joined <- merge(appended_2020, provinsi_appended, by.x =c("provinsi"), by.y = c("provinsi"), all = T)
appended_2020_joined <- merge(appended_2020_joined, kodeprov, by.x = c("nama_kodeprov"), by.y = c("provinsi"), all.x = T)
appended_2020_joined <- appended_2020_joined %>%
dplyr::select(-nama_kodeprov, -(kabupaten:id))
appended_2020_joined <- merge(appended_2020_joined, popdata, by.x = c("kode"), by.y = c("kode_prov"), all.x = T)
# saving the appended data
saveRDS(appended_2020_joined, paste0(wd_2020, "appended_2020.rds"))
